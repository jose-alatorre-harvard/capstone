{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-World Data Demonstration\n",
    "\n",
    "### Team Epsilon-Greedy Quants\n",
    "#### Michael Lee, Nikat Patel, Jose Antonio Alatorre Sanchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates what a user sees when the user runs the User Guide for Real-World Data Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\micha\\anaconda3\\envs\\e599a_py37\\lib\\site-packages\\torch\\lib\\cudnn_adv_train64_8.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-af918afbc0d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0menvironments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me_greedy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeepTradingEnvironment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearAgent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\CSCI E-599a Data Science Capstone\\capstone\\environments\\e_greedy.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDailyDataFrame2Features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\e599a_py37\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf' Error loading \"{dll}\" or one of its dependencies.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\micha\\anaconda3\\envs\\e599a_py37\\lib\\site-packages\\torch\\lib\\cudnn_adv_train64_8.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "from environments.e_greedy import DeepTradingEnvironment, LinearAgent\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt.plotting import plot_efficient_frontier\n",
    "from pypfopt.cla import CLA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import copy\n",
    "import quantstats as qs\n",
    "qs.extend_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "data_env = root+\"/data_env/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _retrieve_asset_dict():\n",
    "    # obtain close prices from parquet files of ETF price history\n",
    "    root = os.getcwd()\n",
    "    data_env = root+\"/data_env_MTUM-EFAV/\"\n",
    "    files = [_ for _ in os.listdir(data_env) if \"parquet\" in _]\n",
    "    assets_dict = {file: pd.read_parquet(data_env + \"/\" + file) for file in files}\n",
    "    counter=0\n",
    "    for key, value in assets_dict.items():\n",
    "        if counter==0:\n",
    "            main_index=value.index\n",
    "    else:\n",
    "        main_index=main_index.join(value.index,how=\"inner\")\n",
    "        \n",
    "    for key, value in assets_dict.items():\n",
    "        tmp_df=value.reindex(main_index)\n",
    "        tmp_df=tmp_df.fillna(method='ffill')\n",
    "        assets_dict[key]=tmp_df['close']\n",
    "    return assets_dict\n",
    "\n",
    "def build_portfolio_df(asset_dict):\n",
    "    portfolio_df = pd.DataFrame()\n",
    "    \n",
    "    for key, value in assets_dict.items():\n",
    "        key = key.split(\".\")[0]\n",
    "        tmp_df = pd.DataFrame(data=value)\n",
    "        tmp_df.columns=[key]\n",
    "        portfolio_df = pd.concat([portfolio_df, tmp_df], axis=1)\n",
    "        \n",
    "    portfolio_df.index = pd.to_datetime(portfolio_df.index, errors='coerce')\n",
    "    return portfolio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_backtest(linear_agent_train, env_test, test_input, model_run, model):\n",
    "    ## Create plot of backtest returns\n",
    "    if not \"backtest\" in locals():\n",
    "        backtest=None\n",
    "    backtest, tmp_weights =linear_agent_train.backtest_policy(epoch=1,backtest=backtest, env_test=env_test, test_input=test_input)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(backtest,color=\"blue\")\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.xlabel(\"Date\", fontsize = 10)\n",
    "    plt.ylabel(\"Backtest\", fontsize = 10)\n",
    "    plt.title(\"Backtest on Test Data: \"+ model,fontsize = 16)\n",
    "    plt.savefig(root+'/temp_persisted_data/'+model_run+\"_test_backtest_plot_\"+model+'.png')\n",
    "    tmp_weights.to_csv(root+'/temp_persisted_data/'+model_run+\"_test_backtest_weights_\"+model+'.csv')\n",
    "    plt.show()\n",
    "    return backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing Real-World Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a sample ETF\n",
    "\n",
    "data_env_two_asset = root+ \"/data_env_MTUM-EFAV/\"\n",
    "\n",
    "pd.read_parquet(data_env_two_asset+'EFAV.parquet').head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a portfolio\n",
    "assets_dict = _retrieve_asset_dict()\n",
    "portfolio_df = build_portfolio_df(assets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train dataset and de-mean the time series\n",
    "\n",
    "portfolio_df_train = portfolio_df[portfolio_df.index >= '2019-02-01']\n",
    "portfolio_df_train = portfolio_df_train[portfolio_df_train.index <= '2020-02-01']\n",
    "portfolio_df_train.sub(portfolio_df_train.mean())\n",
    "\n",
    "portfolio_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test dataset consisting of 6 months of data and de-mean the time series\n",
    "\n",
    "portfolio_df_test = portfolio_df[portfolio_df.index >= '2020-04-16']\n",
    "portfolio_df_test = portfolio_df_test[portfolio_df_test.index <= '2020-11-16']\n",
    "portfolio_df_test.sub(portfolio_df_test.mean())\n",
    "\n",
    "portfolio_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_returns = portfolio_df_test.to_returns().dropna()\n",
    "test_input_returns = test_input_returns.loc[(test_input_returns != 0).any(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters related to the transformation of data, this parameters govern an step before the algorithm\n",
    "out_reward_window=datetime.timedelta(days=7)\n",
    "\n",
    "meta_parameters = {\"in_bars_count\": 1,\n",
    "                   \"out_reward_window\":out_reward_window ,\n",
    "                   \"state_type\":\"in_window_out_window\",\n",
    "                   \"risk_aversion\":1,\n",
    "                   \"include_previous_weights\":False}\n",
    "\n",
    "# parameters that are related to the objective/reward function construction\n",
    "objective_parameters = {\"percent_commission\": .001}\n",
    "\n",
    "print(\"===Meta Parameters===\")\n",
    "print(meta_parameters)\n",
    "print(\"===Objective Parameters===\")\n",
    "print(objective_parameters)\n",
    "\n",
    "detrend=True\n",
    "\n",
    "# create an environment and build features based on Real-World Dataset located in the \"data_env\" folder \n",
    "env = DeepTradingEnvironment.build_environment_from_dirs_and_transform(meta_parameters, objective_parameters,data_hash=\"MTUM-EFAV\", data_dir=\"data_env_MTUM-EFAV\", detrend=detrend)\n",
    "\n",
    "number_of_assets = env.number_of_assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Features and Forward Returns into Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_parquet(\"temp_persisted_data/only_features_MTUM-EFAV\")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_parquet(\"temp_persisted_data/only_features_MTUM-EFAV\")\n",
    "\n",
    "features_train = features[features.index >= '2019-02-01']\n",
    "features_train = features_train[features_train.index <= '2020-02-01']\n",
    "\n",
    "features_test = features[features.index >= '2020-04-16']\n",
    "features_test = features_test[features_test.index <= '2020-11-16']\n",
    "\n",
    "\n",
    "features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_return_dates = pd.read_parquet(\"temp_persisted_data/forward_return_dates_MTUM-EFAV\")\n",
    "\n",
    "forward_return_dates_train = forward_return_dates[forward_return_dates.index >= '2019-02-01']\n",
    "forward_return_dates_train = forward_return_dates_train[forward_return_dates_train.index <= '2020-02-01']\n",
    "\n",
    "forward_return_dates_test = forward_return_dates[forward_return_dates.index > '2020-04-16']\n",
    "forward_return_dates_test = forward_return_dates_test[forward_return_dates_test.index <= '2020-11-16']\n",
    "\n",
    "forward_return_dates_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_returns = pd.read_parquet(\"temp_persisted_data/only_forward_returns_MTUM-EFAV\")\n",
    "\n",
    "forward_returns_train = forward_returns[forward_returns.index >= '2019-02-01']\n",
    "forward_returns_train = forward_returns_train[forward_returns_train.index <= '2020-02-01']\n",
    "forward_returns_train.sub(forward_returns_train.mean())\n",
    "\n",
    "forward_returns_test = forward_returns[forward_returns.index >= '2020-04-16']\n",
    "forward_returns_test = forward_returns_test[forward_returns_test.index <= '2020-11-16']\n",
    "forward_returns_test.sub(forward_returns_test.mean())\n",
    "\n",
    "forward_returns_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Policy-Gradient Method Algorithms on Real-World Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 4001\n",
    "model_run = \"MTUM-EFAV_lambda_1\"\n",
    "sample_observations = 32\n",
    "plot_interval = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create environment and run REINFORCE\n",
    "\n",
    "env_reinforce_train=DeepTradingEnvironment(features_train, forward_returns_train, forward_return_dates_train, objective_parameters,\n",
    "                 meta_parameters)\n",
    "env_reinforce_test = DeepTradingEnvironment(features_test, forward_returns_test, forward_return_dates_test, objective_parameters,\n",
    "                 meta_parameters)\n",
    "\n",
    "linear_agent_reinforce = LinearAgent(environment=env_reinforce_train,out_reward_window_td=out_reward_window, reward_function=\"return_with_variance_risk\",sample_observations=sample_observations)\n",
    "linear_agent_reinforce._load_benchmark(portfolio_df)\n",
    "linear_agent_reinforce.REINFORCE_fit(max_iterations=max_iter, add_baseline=False, plot_every = plot_interval, train_input = portfolio_df_train, model_run = model_run, detrend=detrend, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform backtest \n",
    "backtest_reinforce = plot_backtest(linear_agent_reinforce, env_reinforce_test, portfolio_df_test, model_run, model=\"REINFORCE\")\n",
    "backtest_reinforce.to_csv('temp_persisted_data/'+model_run+'_backtest_reinforce.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_input_returns+1).cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_input_returns.sum(axis=1)+1).cumprod().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REINFORCE with Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create environment and run REINFORCE with baseline\n",
    "env_reinforce_baseline_train = DeepTradingEnvironment(features_train, forward_returns_train, forward_return_dates_train, objective_parameters,\n",
    "                 meta_parameters)\n",
    "env_reinforce_baseline_test = DeepTradingEnvironment(features_test, forward_returns_test, forward_return_dates_test, objective_parameters,\n",
    "                 meta_parameters)\n",
    "\n",
    "linear_agent_reinforce_baseline = LinearAgent(environment=env_reinforce_baseline_train,out_reward_window_td=out_reward_window, reward_function=\"return_with_variance_risk\",sample_observations=sample_observations)\n",
    "linear_agent_reinforce_baseline._load_benchmark(portfolio_df)\n",
    "linear_agent_reinforce_baseline.REINFORCE_fit(max_iterations=max_iter, add_baseline=True, plot_every = plot_interval, train_input = portfolio_df_train, model_run = model_run, detrend=detrend, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform backtest \n",
    "backtest_reinforce_baseline = plot_backtest(linear_agent_reinforce_baseline, env_reinforce_baseline_test, portfolio_df_test, model_run, model=\"REINFORCE with Baseline\")\n",
    "backtest_reinforce_baseline.to_csv('temp_persisted_data/'+model_run+'_backtest_reinforce_baseline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor-Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create environment and run Actor-Critic \n",
    "\n",
    "env_actor_critic_no_trace_train = DeepTradingEnvironment(features_train, forward_returns_train, forward_return_dates_train, objective_parameters,\n",
    "                 meta_parameters)\n",
    "env_actor_critic_no_trace_test = DeepTradingEnvironment(features_test, forward_returns_test, forward_return_dates_test, objective_parameters,\n",
    "                 meta_parameters)\n",
    "\n",
    "linear_agent_actor_critic_no_trace = LinearAgent(environment=env_actor_critic_no_trace_train,out_reward_window_td=out_reward_window, reward_function=\"return_with_variance_risk\",sample_observations=sample_observations)\n",
    "linear_agent_actor_critic_no_trace._load_benchmark(portfolio_df)\n",
    "linear_agent_actor_critic_no_trace.ACTOR_CRITIC_FIT(use_traces=False,max_iterations=max_iter, plot_every = plot_interval,train_input = portfolio_df_train, model_run = model_run, detrend=detrend, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform backtest\n",
    "backtest_actor_critic_no_trace = plot_backtest(linear_agent_actor_critic_no_trace, env_actor_critic_no_trace_test,  portfolio_df_test, model_run, model=\"Actor-Critic without Eligibility Traces\")\n",
    "backtest_actor_critic_no_trace.to_csv('temp_persisted_data/'+model_run+'_backtest_actor_critic_no_trace.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor-Critic with Eligibility Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create environment and run Actor-Critic with Eligibility Traces \n",
    "env_actor_critic_trace_train = DeepTradingEnvironment(features_train, forward_returns_train, forward_return_dates_train, objective_parameters,\n",
    "                 meta_parameters)\n",
    "env_actor_critic_trace_test = DeepTradingEnvironment(features_test, forward_returns_test, forward_return_dates_test, objective_parameters,\n",
    "                 meta_parameters)\n",
    "\n",
    "linear_agent_actor_critic_trace = LinearAgent(environment=env_actor_critic_trace_train,out_reward_window_td=out_reward_window, reward_function=\"return_with_variance_risk\",sample_observations=sample_observations)\n",
    "linear_agent_actor_critic_trace._load_benchmark(portfolio_df)\n",
    "linear_agent_actor_critic_trace.ACTOR_CRITIC_FIT(use_traces=True,max_iterations=max_iter, plot_every = plot_interval,train_input = portfolio_df_train, model_run = model_run, detrend=detrend, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform backtest \n",
    "backtest_actor_critic_trace = plot_backtest(linear_agent_actor_critic_trace, env_actor_critic_trace_test,  portfolio_df_test, model_run, model=\"Actor-Critic with Eligibility Traces\")\n",
    "backtest_actor_critic_trace.to_csv('temp_persisted_data/'+model_run+'_backtest_actor_critic_trace.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e599a_py37",
   "language": "python",
   "name": "e599a_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
